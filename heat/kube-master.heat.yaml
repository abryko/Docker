heat_template_version: 2013-05-23

parameters:
  public_ip:
    label: public_ip
    type: string
  pool_id:
    label: pool id
    type: string
  floating_ip:
    label: floating_ip
    type: string
  vpn_username:
    label: vpn_username
    type: string
  vpn_password:
    label: vpn_password
    type: string
  nodename:
    label: nodename
    type: string
  nodeip:
    label: nodename
    type: string
  subnet:
    label: subnet
    type: string
  os_username:
    label: os_username
    type: string
  os_password:
    label: os_password
    type: string
  os_tenant:
    label: os_tenant
    type: string
  os_auth:
    label: os_auth
    type: string
  network:
    label: network
    type: string
  security_group:
    label: security_group
    type: string
  keypair_name:
    description: Keypair to inject in instance
    label: SSH Keypair
    type: string
  domain:
    description: Wildcarded domain, ex example.com must have a *.example.com DNS entry
    label: Cloud DNS
    type: string
  flavor_name:
    label: Instance Type (Flavor)
    description: Flavor to use for the deployed instance
    type: string

resources:
  port:
    type: OS::Neutron::Port
    properties:
      network: { get_param: network }
      fixed_ips:
        - ip_address: { get_param: nodeip }
          subnet_id: { get_param: subnet }
      security_groups:
        - { get_param: security_group }

  member:
    type: OS::Neutron::PoolMember
    properties:
      pool_id: {get_param: pool_id}
      address: {get_attr: [master , first_address]}
      protocol_port: 443

  master:
    type: OS::Nova::Server
    properties:
      key_name: { get_param: keypair_name }
      image: CoreOS Stable 899.13
      flavor: { get_param: flavor_name }
      user_data_format: RAW
      name: { get_param: nodename}
      networks:
        - port: { get_resource: port }
      user_data:
        str_replace:
          params:
            $private_ipv4: { get_attr: [ port, fixed_ips, 0, ip_address ] }
            $fqdn: { get_param: nodename }
            $public_ipv4: { get_param: public_ip }
            $domain: { get_param: domain }
            $os_username: { get_param: os_username}
            $os_password: { get_param: os_password}
            $os_tenant: { get_param: os_tenant }
            $os_auth: { get_param: os_auth }
            $vpn_username: { get_param: vpn_username }
            $vpn_password: { get_param: vpn_password }
          template: |
            #cloud-config
            write_files:
              - path: /etc/flannel/options.env
                permissions: 0644
                owner: "root:root"
                content: |
                  FLANNELD_IFACE=$private_ipv4
                  FLANNELD_ETCD_ENDPOINTS=http://localhost:2379
              - path: /opt/bin/kubelet-wrapper
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  # Wrapper for launching kubelet via rkt-fly stage1.
                  #
                  # Make sure to set KUBELET_VERSION to an image tag published here:
                  # https://quay.io/repository/coreos/hyperkube?tab=tags Alternatively,
                  # override $KUBELET_ACI to a custom location.

                  set -e

                  if [ -z "${KUBELET_VERSION}" ]; then
                      echo "ERROR: must set KUBELET_VERSION"
                      exit 1
                  fi

                  KUBELET_ACI="${KUBELET_ACI:-quay.io/coreos/hyperkube}"

                  mkdir --parents /etc/kubernetes
                  mkdir --parents /var/lib/docker
                  mkdir --parents /var/lib/kubelet
                  mkdir --parents /run/kubelet

                  exec /usr/bin/rkt run \
                    --volume etc-kubernetes,kind=host,source=/etc/kubernetes \
                    --volume etc-kubernetes-ssl,kind=host,source=/etc/kubernetes/ssl \
                    --volume etc-ssl-certs,kind=host,source=/usr/share/ca-certificates \
                    --volume var-lib-docker,kind=host,source=/var/lib/docker \
                    --volume var-lib-kubelet,kind=host,source=/var/lib/kubelet \
                    --volume run,kind=host,source=/run \
                    --mount volume=etc-kubernetes,target=/etc/kubernetes \
                    --mount volume=etc-kubernetes-ssl,target=/etc/kubernetes/ssl \
                    --mount volume=etc-ssl-certs,target=/etc/ssl/certs \
                    --mount volume=var-lib-docker,target=/var/lib/docker \
                    --mount volume=var-lib-kubelet,target=/var/lib/kubelet \
                    --mount volume=run,target=/run \
                    --trust-keys-from-https \
                    $RKT_OPTS \
                    --stage1-path=/usr/share/rkt/stage1-fly.aci \
                    ${KUBELET_ACI}:${KUBELET_VERSION} --exec=/kubelet -- "$@"
              - path: /opt/kubernetes-init-ssl.sh
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  mkdir -p /etc/kubernetes/ssl
                  cd /etc/kubernetes/ssl
                  echo "Waiting for etcd..."
                  ETCD="http://$private_ipv4:2379"
                  until curl -s $ETCD/v2/keys/ssl/ca|grep CERTIFICATE
                  do
                      echo "Trying: $ETCD"
                      sleep 1
                  done
                  etcdctl get /ssl/ca > ca.pem
                  etcdctl get /ssl/key > ca-key.pem
                  etcdctl get /ssl/admin > admin.pem
                  etcdctl get /ssl/admin-key > admin-key.pem
                  etcdctl get /ssl/apiserver > apiserver.pem
                  etcdctl get /ssl/apiserver-key > apiserver-key.pem
                  # Set permissions
                  chmod 600 /etc/kubernetes/ssl/*-key.pem
                  chown root:root /etc/kubernetes/ssl/*-key.pem
              - path: /opt/kube-resources-init.sh
                permissions: 0700
                owner: "root:root"
                content: |
                  #!/bin/bash
                  # Secret
                  cat <<EOF > /etc/kubernetes/descriptors/0-secret.yaml
                  apiVersion: v1
                  kind: Secret
                  metadata:
                    name: openstack
                  type: Opaque
                  data:
                    password: $(echo -n '$os_password' | base64)
                    username: $(echo -n '$os_username' | base64)
                  EOF
                  echo "Waiting for Kubernetes API..."
                  K8S="http://$private_ipv4:8080"
                  until curl --silent "$K8S/version"
                  do
                      echo "Trying: $K8S"
                      sleep 1
                  done
                  RES=$(curl -H "Content-Type: application/json" -XPOST -d'{"apiVersion":"v1","kind":"Namespace","metadata":{"name":"kube-system"}}' "http://127.0.0.1:8080/api/v1/namespaces")
                  if [ -z "$(echo $RES | grep '"phase": "Active"')" ]; then
                      echo "Unexpected error configuring Kubernetes Namespace : $RES"
                  else
                      echo "Created kube-system namespace"
                  fi
                  mkdir -p /opt/bin
                  curl -o /opt/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.2.4/bin/linux/amd64/kubectl
                  chmod +x /opt/bin/kubectl
                  ret=$(kubectl get secret openstack)
                  if [ "$?" -eq "1" ]; then
                    /opt/bin/kubectl create -f /etc/kubernetes/descriptors
                  fi
              - path: /etc/kubernetes/manifests/kube-apiserver.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Pod
                  metadata:
                    name: kube-apiserver
                    namespace: kube-system
                  spec:
                    hostNetwork: true
                    containers:
                    - name: kube-apiserver
                      image: quay.io/coreos/hyperkube:v1.2.4_coreos.1
                      command:
                      - /hyperkube
                      - apiserver
                      - --bind-address=0.0.0.0
                      - --insecure-bind-address=0.0.0.0
                      - --etcd-servers=http://$private_ipv4:2379
                      - --allow-privileged=true
                      - --service-cluster-ip-range=10.0.2.0/24
                      - --service-node-port-range=1-33000
                      - --secure-port=443
                      - --advertise-address=$private_ipv4
                      - --admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota
                      - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
                      - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
                      - --client-ca-file=/etc/kubernetes/ssl/ca.pem
                      - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem
                      ports:
                      - containerPort: 443
                        name: https
                      - containerPort: 8080
                        name: local
                      volumeMounts:
                      - mountPath: /etc/kubernetes/ssl
                        name: ssl-certs-kubernetes
                        readOnly: true
                      - mountPath: /etc/ssl/certs
                        name: ssl-certs-host
                        readOnly: true
                    volumes:
                    - hostPath:
                        path: /etc/kubernetes/ssl
                      name: ssl-certs-kubernetes
                    - hostPath:
                        path: /usr/share/ca-certificates
                      name: ssl-certs-host
              - path: /etc/kubernetes/manifests/kube-proxy.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Pod
                  metadata:
                    name: kube-proxy
                    namespace: kube-system
                  spec:
                    hostNetwork: true
                    containers:
                    - name: kube-proxy
                      image: quay.io/coreos/hyperkube:v1.2.4_coreos.1
                      command:
                      - /hyperkube
                      - proxy
                      - --master=http://127.0.0.1:8080
                      - --proxy-mode=iptables
                      securityContext:
                        privileged: true
                      volumeMounts:
                      - mountPath: /etc/ssl/certs
                        name: ssl-certs-host
                        readOnly: true
                    volumes:
                    - hostPath:
                        path: /usr/share/ca-certificates
                      name: ssl-certs-host
              - path: /etc/kubernetes/manifests/kube-controller-manager.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Pod
                  metadata:
                    name: kube-controller-manager
                    namespace: kube-system
                  spec:
                    hostNetwork: true
                    containers:
                    - name: kube-controller-manager
                      image: quay.io/coreos/hyperkube:v1.2.4_coreos.1
                      command:
                      - /hyperkube
                      - controller-manager
                      - --master=http://127.0.0.1:8080
                      - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
                      - --root-ca-file=/etc/kubernetes/ssl/ca.pem
                      livenessProbe:
                        httpGet:
                          host: 127.0.0.1
                          path: /healthz
                          port: 10252
                        initialDelaySeconds: 15
                        timeoutSeconds: 1
                      volumeMounts:
                      - mountPath: /etc/kubernetes/ssl
                        name: ssl-certs-kubernetes
                        readOnly: true
                      - mountPath: /etc/ssl/certs
                        name: ssl-certs-host
                        readOnly: true
                    volumes:
                    - hostPath:
                        path: /etc/kubernetes/ssl
                      name: ssl-certs-kubernetes
                    - hostPath:
                        path: /usr/share/ca-certificates
                      name: ssl-certs-host
              - path: /etc/kubernetes/manifests/kube-scheduler.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  kind: Pod
                  metadata:
                    name: kube-scheduler
                    namespace: kube-system
                  spec:
                    hostNetwork: true
                    containers:
                    - name: kube-scheduler
                      image: quay.io/coreos/hyperkube:v1.2.4_coreos.1
                      command:
                      - /hyperkube
                      - scheduler
                      - --master=http://127.0.0.1:8080
                      - --leader-elect=true
                      livenessProbe:
                        httpGet:
                          host: 127.0.0.1
                          path: /healthz
                          port: 10251
                        initialDelaySeconds: 15
                        timeoutSeconds: 1
              - path: /etc/kubernetes/descriptors/0-flocker.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  items:
                    - apiVersion: v1
                      kind: ServiceAccount
                      metadata:
                        name: flocker
                        namespace: kube-system
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        name: flocker-control
                        namespace: kube-system
                        labels:
                          component: flocker
                          role: control
                      spec:
                        selector:
                          component: flocker
                          role: control
                        ports:
                        - name: api
                          port: 4523
                          protocol: TCP
                        - name: agent
                          port: 4524
                          protocol: TCP
                    - apiVersion: v1
                      kind: ReplicationController
                      metadata:
                        name: flocker-control
                        namespace: kube-system
                        labels:
                          component: flocker
                          role: control
                      spec:
                        replicas: 1
                        selector:
                          component: flocker
                          role: control
                        template:
                          metadata:
                            namespace: kube-system
                            labels:
                              component: flocker
                              role: control
                          spec:
                            hostPID: true
                            hostIPC: true
                            hostNetwork: true
                            serviceAccount: flocker
                            containers:
                              - name: flocker-control
                                securityContext:
                                  privileged: true
                                image: clusterhq/flocker-control-service
                                imagePullPolicy: Always
                                volumeMounts:
                                  - name: flocker-control-etc
                                    mountPath: /etc/flocker
                                    readOnly: true
                                  - name: var-lib-docker
                                    mountPath: /var/lib/flocker
                                ports:
                                - containerPort: 4523
                                  name: api
                                  protocol: TCP
                                - containerPort: 4524
                                  name: agent
                                  protocol: TCP
                            volumes:
                              - name: flocker-control-etc
                                secret:
                                  secretName: flocker-control-etc
                              - name: var-lib-docker
                                emptyDir: {}
                    -
              - path: /etc/kubernetes/descriptors/1-skydns.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  items:
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        name: kube-dns
                        namespace: kube-system
                        labels:
                          k8s-app: kube-dns
                          kubernetes.io/cluster-service: "true"
                          kubernetes.io/name: "KubeDNS"
                      spec:
                        selector:
                          k8s-app: kube-dns
                        clusterIP: 10.0.2.2
                        ports:
                        - name: dns
                          port: 53
                          protocol: UDP
                        - name: dns-tcp
                          port: 53
                          protocol: TCP
                    - apiVersion: v1
                      kind: ReplicationController
                      metadata:
                        name: kube-dns-v11
                        namespace: kube-system
                        labels:
                          k8s-app: kube-dns
                          version: v11
                          kubernetes.io/cluster-service: "true"
                      spec:
                        replicas: 1
                        selector:
                          k8s-app: kube-dns
                          version: v11
                        template:
                          metadata:
                            labels:
                              k8s-app: kube-dns
                              version: v11
                              kubernetes.io/cluster-service: "true"
                          spec:
                            containers:
                            - name: etcd
                              image: gcr.io/google_containers/etcd-amd64:2.2.1
                              resources:
                                limits:
                                  cpu: 100m
                                  memory: 500Mi
                                requests:
                                  cpu: 100m
                                  memory: 50Mi
                              command:
                              - /usr/local/bin/etcd
                              - -data-dir
                              - /var/etcd/data
                              - -listen-client-urls
                              - http://127.0.0.1:2379,http://127.0.0.1:4001
                              - -advertise-client-urls
                              - http://127.0.0.1:2379,http://127.0.0.1:4001
                              - -initial-cluster-token
                              - skydns-etcd
                              volumeMounts:
                              - name: etcd-storage
                                mountPath: /var/etcd/data
                            - name: kube2sky
                              image: gcr.io/google_containers/kube2sky:1.14
                              resources:
                                limits:
                                  cpu: 100m
                                  memory: 200Mi
                                requests:
                                  cpu: 100m
                                  memory: 50Mi
                              livenessProbe:
                                httpGet:
                                  path: /healthz
                                  port: 8080
                                  scheme: HTTP
                                initialDelaySeconds: 60
                                timeoutSeconds: 5
                                successThreshold: 1
                                failureThreshold: 5
                              readinessProbe:
                                httpGet:
                                  path: /readiness
                                  port: 8081
                                  scheme: HTTP
                                initialDelaySeconds: 30
                                timeoutSeconds: 5
                              args:
                              # command = "/kube2sky"
                              - --domain=$domain
                            - name: skydns
                              image: gcr.io/google_containers/skydns:2015-10-13-8c72f8c
                              resources:
                                limits:
                                  cpu: 100m
                                  memory: 200Mi
                                requests:
                                  cpu: 100m
                                  memory: 50Mi
                              args:
                              - -machines=http://127.0.0.1:4001
                              - -addr=0.0.0.0:53
                              - -ns-rotate=false
                              - -domain=$domain.
                              ports:
                              - containerPort: 53
                                name: dns
                                protocol: UDP
                              - containerPort: 53
                                name: dns-tcp
                                protocol: TCP
                            - name: healthz
                              image: gcr.io/google_containers/exechealthz:1.0
                              resources:
                                # keep request = limit to keep this container in guaranteed class
                                limits:
                                  cpu: 10m
                                  memory: 20Mi
                                requests:
                                  cpu: 10m
                                  memory: 20Mi
                              args:
                              - -cmd=nslookup kubernetes.default.svc.$domain 127.0.0.1 >/dev/null
                              - -port=8080
                              ports:
                              - containerPort: 8080
                                protocol: TCP
                            volumes:
                            - name: etcd-storage
                              emptyDir: {}
                            dnsPolicy: Default  # Don't use cluster DNS.
              - path: /etc/kubernetes/descriptors/2-rabbitmq.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  items:
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        labels:
                          component: rabbitmq
                        name: rabbitmq
                      spec:
                        sessionAffinity: ClientIP
                        ports:
                          - port: 5672
                            name: main
                          - port: 15672
                            name: management
                        selector:
                          component: rabbitmq
                    - apiVersion: v1
                      kind: ReplicationController
                      metadata:
                        labels:
                          component: rabbitmq
                        name: rabbitmq-controller
                      spec:
                        replicas: 1
                        template:
                          metadata:
                            labels:
                              component: rabbitmq
                          spec:
                            containers:
                              - image: rabbitmq:management
                                name: rabbitmq
                                ports:
                                  - containerPort: 5672
                                  - containerPort: 15672
                                resources:
                                  limits:
                                    cpu: 100m
              - path: /etc/kubernetes/descriptors/3-rethinkdb.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  items:
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        labels:
                          db: rethinkdb
                        name: rethinkdb-driver
                      spec:
                        sessionAffinity: ClientIP
                        ports:
                          - port: 28015
                            targetPort: 28015
                            name: driver
                          - port: 80
                            targetPort: 8080
                            name: web
                        selector:
                          db: rethinkdb
                    - apiVersion: v1
                      kind: ReplicationController
                      metadata:
                        labels:
                          db: rethinkdb
                        name: rethinkdb-rc
                      spec:
                        replicas: 1
                        selector:
                          db: rethinkdb
                          role: replicas
                        template:
                          metadata:
                            labels:
                              db: rethinkdb
                              role: replicas
                          spec:
                            containers:
                              - image: rethinkdb
                                name: rethinkdb
                                command:
                                  - rethinkdb
                                  - --bind
                                  - all
                                  - -n
                                  - rethinkdb
                                ports:
                                  - containerPort: 8080
                                    name: admin-port
                                  - containerPort: 28015
                                    name: driver-port
                                  - containerPort: 29015
                                    name: cluster-port
                                volumeMounts:
                                  - mountPath: /data/rethinkdb_data
                                    name: rethinkdb-storage
                            volumes:
                              - name: rethinkdb-storage
                                hostPath:
                                  path: /data/rethinkdb
              - path: /etc/kubernetes/descriptors/4-toolbox.yaml
                permissions: 0666
                owner: "root:root"
                content: |
                  apiVersion: v1
                  items:
                    - apiVersion: v1
                      kind: Service
                      metadata:
                        labels:
                          component: toolbox
                        name: manager
                      spec:
                        sessionAffinity: ClientIP
                        ports:
                          - port: 80
                            targetPort: 3000
                            nodePort: 30000
                        type: NodePort
                        selector:
                          component: toolbox
                    - apiVersion: extensions/v1beta1
                      kind: Deployment
                      metadata:
                        labels:
                          component: toolbox
                        name: toolbox
                      spec:
                        replicas: 1
                        template:
                          metadata:
                            labels:
                              component: toolbox
                          spec:
                            containers:
                              - image: cloudwattfr/toolbox:2.0
                                imagePullPolicy: Always
                                command:
                                  - npm
                                  - start
                                  - $private_ipv4
                                  - $public_ipv4
                                name: toolbox
                                env:
                                  - name: DOMAIN
                                    value: "$domain"
                                  - name: OS_AUTH_URL
                                    value: "$os_auth"
                                  - name: OS_TENANT_NAME
                                    value: "$os_tenant"
                                  - name: OS_USERNAME
                                    valueFrom:
                                      secretKeyRef:
                                        name: openstack
                                        key: username
                                  - name: OS_PASSWORD
                                    valueFrom:
                                      secretKeyRef:
                                        name: openstack
                                        key: password
                                  - name: REPLICAS
                                    value: "1"
                                ports:
                                  - containerPort: 3000
                                volumeMounts:
                                  - mountPath: /keys
                                    name: key-storage
                            volumes:
                              - name: key-storage
                                hostPath:
                                  path: /home/core/keys
              - path: /etc/environment
                permissions: 0666
                owner: "root:root"
                content: |
                  COREOS_PRIVATE_IPV4=$private_ipv4
                  COREOS_PUBLIC_IPV4=$public_ipv4
                  ETCD_ADDR=$private_ipv4:2379
                  ETCD_PEER_ADDR=$private_ipv4:2380
                  TOOLBOX_DOMAIN=$domain

            coreos:
              etcd2:
                proxy: on
                listen-client-urls: http://0.0.0.0:2379
                initial-cluster: etcdserver=http://10.0.1.2:2380
              units:
                - name: etcd2.service
                  command: start
                - name: flanneld.service
                  drop-ins:
                    - name: 40-ExecStartPre-symlink.conf
                      content: |
                        [Service]
                        ExecStartPre=/usr/bin/ln -sf /etc/flannel/options.env /run/flannel/options.env
                - name: docker.service
                  drop-ins:
                    - name: 40-flannel.conf
                      content: |
                        [Unit]
                        Requires=flanneld.service
                        After=flanneld.service
                - name: generatessl.service
                  command: start
                  content: |
                    [Unit]
                    Requires=etcd2.service
                    After=etcd2.service
                    ConditionPathExists=!/etc/kubernetes/ssl/apiserver.pem
                    Description=Kubernetes Keys Retriever

                    [Service]
                    Type=oneshot
                    ExecStart=/opt/kubernetes-init-ssl.sh
                - name: kubelet.service
                  command: start
                  content: |
                    [Unit]
                    Requires=generatessl.service
                    After=generatessl.service

                    [Service]
                    ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
                    Environment=KUBELET_VERSION=v1.2.4_coreos.1
                    Environment="RKT_OPTS=--volume dns,kind=host,source=/etc/resolv.conf --mount volume=dns,target=/etc/resolv.conf \
                        --volume flocker-etc,kind=host,source=/etc/flocker --mount volume=flocker-etc,target=/etc/flocker \
                        --set-env=FLOCKER_CONTROL_SERVICE_HOST={{api-endpoint}} \
                        --set-env=FLOCKER_CONTROL_SERVICE_PORT=4523 \
                        --set-env=FLOCKER_CONTROL_SERVICE_CA_FILE=/etc/flocker/cluster.crt \
                        --set-env=FLOCKER_CONTROL_SERVICE_CLIENT_KEY_FILE=/etc/flocker/kubelet.key \
                        --set-env=FLOCKER_CONTROL_SERVICE_CLIENT_CERT_FILE=/etc/flocker/kubelet.crt"
                    ExecStart=/opt/bin/kubelet-wrapper \
                      --api-servers=http://127.0.0.1:8080 \
                      --register-schedulable=false \
                      --register-node=true \
                      --allow-privileged=true \
                      --config=/etc/kubernetes/manifests \
                      --hostname-override=$private_ipv4 \
                      --cluster-dns=10.0.2.2 \
                      --cluster-domain=$domain
                    ExecStartPost=-/opt/kube-resources-init.sh
                    Restart=always
                    RestartSec=10
                    [Install]
                    WantedBy=multi-user.target
                - name: pptp.service
                  command: start
                  content: |
                    [Unit]
                    Description=PPTP
                    After=docker.service
                    Requires=docker.service
                    [Service]
                    TimeoutStartSec=0
                    Restart=always
                    RestartSec=10
                    ExecStartPre=-/usr/bin/docker kill pptp
                    ExecStartPre=-/usr/bin/docker rm pptp
                    ExecStartPre=/usr/bin/docker pull cedbossneo/pptp
                    ExecStart=/bin/bash -c "\
                      docker run \
                        --name pptp \
                        --privileged \
                        --net=host \
                        --env 'USERNAME=$vpn_username' \
                        --env 'PASSWORD=$vpn_password' \
                        cedbossneo/pptp \
                    "
                    ExecStop=/usr/bin/docker stop pptp

  floating_ip_link:
    type: OS::Nova::FloatingIPAssociation
    properties:
      floating_ip: { get_param: floating_ip }
      server_id: { get_resource: master }
